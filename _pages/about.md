---
permalink: /
excerpt: "About"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

<br>

<font size="+0.2">
Hi, „Åì„Çì„Å´„Å°„ÅØ, ‰Ω†Â•Ω :-)
<br><br>

Zhihang Zhong is a researcher at <a href="https://www.shlab.org.cn/" target="_blank">Shanghai AI
Laboratory</a>.<br>
He received his PhD degree in Computer Science and ME degree in Precision Engineering from the University of Tokyo (UTokyo). Before that, he received his BE degree in Mechatronics from Chu Kochen Honors College, Zhejiang University.<br>
<br>
Zhihang's current research interests include: <br>
<b><em>* Spatial Intelligence</em></b><br>
<b><em>* Neural Rendering</em></b><br>
<em>* Computational Photography</em><br>
<br>
<em><b>üî• We are looking for interns and PhD students!</b><br>
If you are interested, please email me: zzh-tech [at] gmail.com</em><br>
</font>

## News

<font size="+0.2">
<details>
    <summary> [see more] <br>
    [2025.12] üöÄ We are thrilled to release <a href="https://visionary-laboratory.github.io/visionary/" target="_blank">Visionary</a>, the <em>World Model Carrier</em>!!<br>
    [2025.11] One paper (Oral) is accepted to AAAI 2026. <br>
    [2025.06] Three papers are accepted to ICCV 2025. <br>
    [2025.02] <a href="https://github.com/kaikai23/maskgaussian" target="_blank">MaskGaussian</a> is accepted to CVPR 2025. <br>
    [2024.08] Our <a href="https://mp.weixin.qq.com/s/dEAAvAupqjAMHczwTUCkhQ?version=4.1.28.6010&platform=win&nwr_flag=1#wechat_redirect" target="_blank">SportsStrat (Êµ¶Âä®) empowers the 2024 Paris Olympics</a>!<br>
    </summary>
    [2024.07] Glad to receive the 2023 <a href="https://en.wikipedia.org/wiki/Chinese_government_award_for_outstanding_self-financed_students_abroad" target="_blank">Chinese Government Award for Outstanding <br>Self-financed Students Abroad (Group B, Global Top 50)</a>!<br>
    [2024.07] Three papers (one Oral) are accepted to ECCV 2024! <br>
    [2024.05] We release <a href="https://mp.weixin.qq.com/s/uBUfvuF09WBMnN_Fm_Ss7w" target="_blank">SportsStrat (Êµ¶Âä®) on CCTV5 in support of the 2024 Thomas & Uber Cups</a>!<br>
    [2024.03] Glad to receive the <a href="https://www.i.u-tokyo.ac.jp/news/topics/2024/202403192381.shtml" target="_blank">Dean's Award for Academic Achievement</a> from the UTokyo! <br>
    [2024.02] Two papers are accepted to CVPR 2024. <br>
    [2023.12] I give a talk at <a href="https://mp.weixin.qq.com/s/9kYeSrJze2Ah7snSqPFLPg" target="_blank"> OpenMMLab</a> about temporal super-resolution. <br>
    [2023.11] Glad to release <a href="https://zzh-tech.github.io/InterpAny-Clearer/" target="_blank">InterpAny-Clearer</a> project! <br>
    [2023.07] Two papers are accepted to ICCV 2023. <br>
    [2023.07] One paper is accepted to ACM-MM 2023. <br>
    [2023.03] I am accepted to CVPR 2023's Doctoral Consortium. <br>
    [2023.02] Two papers are accepted to CVPR 2023. <br>
    [2022.10] I give a talk at <a
                href="https://mipi-challenge.org/#:~:text=Presenter%3A%20Zhihang%20Zhong%20(The%20University%20of%20Tokyo)"
                target="_blank">MIPI Workshop 2022</a>. <br>
    [2022.10] One paper is accepted to IJCV. <br>
    [2022.09] I become a JSPS„ÄåÊó•Êú¨Â≠¶Ë°ìÊåØËàà‰ºö„ÄçDC fellow! <br>
    [2022.07] Three papers (one Oral) are accepted to ECCV 2022! <br>
    [2022.04] I become a JEM intern at Microsoft. <br>
    [2022.03] One paper is accepted to CVPR 2022. <br>
    [2021.09] I become a research intern in the Visual Computing group at MSRA. <br>
    [2021.04] I become a IIW fellow„ÄåÁü•ËÉΩÁ§æ‰ºöÂâµÈÄ†„Éï„Çß„É≠„Éº„Ç∑„ÉÉ„ÉóÁîü„Äçof UTokyo! <br>
    [2021.04] One paper is accepted to IoTJ. <br>
    [2021.02] One paper is accepted to CVPR 2021. <br>
    [2020.11] I become a MSRA D-CORE fellow! <br>
    [2020.09] I obtain my M.E. degree from UTokyo with an outstanding thesis award! <br>
    [2020.07] One paper (Spotlight) is accepted to ECCV 2020! <br>
    [2019.12] One paper is accepted to IUI 2020. <br>
</details>
</font>

## Projects
<b>Visionary:</b><br>
<img src="../images/visionary_teaser.png" width="72%" height="72%"/>

<b>SportsStrat:</b><br>
<img src="../files/ai4sports/badminton_unity_demo.gif" width="72%" height="72%"/>

## Publications

<head>
    <style>
    table,
    th,
    td {
        border: 0px solid darkgray;
    }
    </style><title></title>
</head>

<font size="+0.2">
<sup>*</sup> indicates first author, <sup>‚Ä†</sup> indicates corresponding author
</font>

<table style="width:75%;border:0px;border-spacing:0px;margin-right:auto;margin-left:5px;">
<tbody>
  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Visionary: The World Model Carrier Built on WebGPU-Powered Gaussian Splatting Platform</b>
      <br>
      Yuning Gong, Yifei Liu, Yifan Zhan, Muyao Niu, Xueying Li, Yuanjun Liao, Jiaming Chen, Yuanyuan Gao, Jiaqi Chen, Minming Chen, Li Zhou, Yuning Zhang, Wei Wang, Xiaoqing Hou, Huaxi Huang, Shixiang Tang, Le Ma, Dingwen Zhang, Xue Yang, Junchi Yan, Yanchi Zhang, Yinqiang Zheng, Xiao Sun, <strong>Zhihang Zhong<sup>‚Ä†</sup></strong>
      <br>
      <em>arXiv</em>, 2025<br>
      <a href="https://visionary-laboratory.github.io/visionary/" target="_blank">project</a> /
      <a href="https://arxiv.org/abs/2512.08478" target="_blank">arXiv</a> /
      <a href="https://github.com/Visionary-Laboratory/visionary" target="_blank">code</a> /
      <a href="https://ai4sports.opengvlab.com/index_visionary.html" target="_blank">editor</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>RacketVision: A Multiple Racket Sports Benchmark for Unified Ball and Racket Analysis</b>
      <br>
      Linfeng Dong, Yuchen Yang, Hao Wu, Wei Wang, Yuenan Hou, <strong>Zhihang Zhong<sup>‚Ä†</sup></strong>, Xiao Sun<sup>‚Ä†</sup>
      <br>
      <em>AAAI</em>, 2026, <em style="color: red">Oral</em><br>
      <a href="https://arxiv.org/abs/2511.17045" target="_blank">arXiv</a> /
      <a href="https://github.com/OrcustD/RacketVision" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>CityGS-X: A Scalable Architecture for Efficient and Geometrically Accurate Large-Scale Scene Reconstruction</b>
      <br>
      Yuanyuan Gao, Hao Li, Jiaqi Chen, Zhengyu Zou, <strong>Zhihang Zhong<sup>‚Ä†</sup></strong>, Dingwen Zhang<sup>‚Ä†</sup>,<br>Xiao Sun, Junwei Han
      <br>
      <em>ICCV</em>, 2025 <br>
      <a href="https://lifuguan.github.io/CityGS-X/" target="_blank">project</a> /
      <a href="https://arxiv.org/abs/2503.23044" target="_blank">arXiv</a> /
      <a href="https://github.com/gyy456/CityGS-X" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Sequential Gaussian Avatars with Hierarchical Motion Context</b>
      <br>
      Wangze Xu, Yifan Zhan, <strong>Zhihang Zhong<sup>‚Ä†</sup></strong>, Xiao Sun<sup>‚Ä†</sup>
      <br>
      <em>ICCV</em>, 2025 <br>
      <a href="https://zezeaaa.github.io/projects/SeqAvatar/" target="_blank">project</a> /
      <a href="https://arxiv.org/abs/2411.16768" target="_blank">arXiv</a> /
      <a href="https://github.com/zezeaaa/SeqAvatar" target="_blank">code</a>
    </td>
  </tr>
  
  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Towards Explicit Exoskeleton for the Reconstruction of Complicated 3D Human Avatars</b>
      <br>
      Yifan Zhan, Qingtian Zhu, Muyao Niu, Mingze Ma, Jiancheng Zhao, <strong>Zhihang Zhong<sup>‚Ä†</sup></strong>, <br>Xiao Sun<sup>‚Ä†</sup>, Yu Qiao, Yinqiang Zheng
      <br>
      <em>ICCV</em>, 2025 <br>
      <a href="https://arxiv.org/abs/2410.08082" target="_blank">arXiv</a> /
      <a href="https://github.com/Yifever20002/ToMiE" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks</b>
      <br>
      Yifei Liu, <strong>Zhihang Zhong<sup>‚Ä†</sup></strong>, Yifan Zhan, Sheng Xu, Xiao Sun<sup>‚Ä†</sup>
      <br>
      <em>CVPR</em>, 2025 <br>
      <a href="https://maskgaussian.github.io/" target="_blank">project</a> /
      <a href="https://arxiv.org/abs/2412.20522" target="_blank">arXiv</a> /
      <a href="https://github.com/kaikai23/maskgaussian" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>DiffBody: Human Body Image Restoration with Generative Diffusion Prior</b>
      <br>
      Yiming Zhang, Zhe Wang, Sizhuo Ma, Xinjie Li, Jian Ren, <strong>Zhihang Zhong<sup>‚Ä†</sup></strong>, Jian Wang<sup>‚Ä†</sup>
      <br>
      <em>ICCP</em>, 2025 <br>
      <a href="https://arxiv.org/abs/2404.03642" target="_blank">arXiv</a>
    </td>
  </tr>
  
  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>AniCrafter: Customizing Realistic Human-Centric Animation via Avatar-Background Conditioning in Video Diffusion Models</b>
      <br>
      Muyao Niu, Mingdeng Cao, Yifan Zhan, Qingtian Zhu, Mingze Ma, Jiancheng Zhao, Yanhong Zeng, <strong>Zhihang Zhong<sup>‚Ä†</sup></strong>, Xiao Sun<sup>‚Ä†</sup>, Yinqiang Zheng
      <br>
      <em>arxiv</em>, 2025 <br>
      <a href="https://myniuuu.github.io/AniCrafter/" target="_blank">project</a> /
      <a href="https://www.arxiv.org/abs/2505.20255" target="_blank">arXiv</a> /
      <a href="https://github.com/MyNiuuu/AniCrafter" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>R<sup>3</sup>-Avatar: Record and Retrieve Temporal Codebook for Reconstructing Photorealistic Human Avatars</b>
      <br>
      Yifan Zhan, Wangze Xu, Qingtian Zhu, Muyao Niu, Mingze Ma, Yifei Liu, <strong>Zhihang Zhong<sup>‚Ä†</sup></strong>, <br>Xiao Sun<sup>‚Ä†</sup>, Yinqiang Zheng
      <br>
      <em>arxiv</em>, 2025 <br>
      <a href="https://arxiv.org/abs/2503.12751" target="_blank">arXiv</a> /
      <a href="https://github.com/Yifever20002/R3Avatars" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>SGA-INTERACT: A 3D Skeleton-based Benchmark for Group Activity Understanding in Modern Basketball Tactic</b>
      <br>
      Yuchen Yang, Wei Wang, Yifei Liu, Linfeng Dong, Hao Wu, Mingxin Zhang, <strong>Zhihang Zhong<sup>‚Ä†</sup></strong>, Xiao Sun<sup>‚Ä†</sup>
      <br>
      <em>arxiv</em>, 2025 <br>
      <a href="https://arxiv.org/abs/2503.06522" target="_blank">arXiv</a> /
      <a href="https://github.com/Charrrrrlie/SGA-INTERACT?tab=readme-ov-file" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Disambiguation for Video Frame Interpolation</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Yiming Zhang,
      Wei Wang,
      Xiao Sun,
      Yu Qiao,
      Gurunandan Krishnan,
      Sizhuo Ma,
      Jian Wang
      <br>
      <em>arxiv</em>, 2025
      <br>
      <a href="https://arxiv.org/abs/2311.08007v3" target="_blank">arXiv</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Bundle Adjusted Gaussian Avatars Deblurring</b>
      <br>
      Muyao Niu, Yifan Zhan, Qingtian Zhu, Zhuoxiao Li, Wei Wang, <strong>Zhihang Zhong<sup>‚Ä†</sup></strong>,<br>Xiao Sun<sup>‚Ä†</sup>, Yinqiang Zheng
      <br>
      <em>arXiv</em>, 2024 <br>
      <a href="https://www.arxiv.org/abs/2411.16758" target="_blank">arXiv</a> /
      <a href="https://github.com/MyNiuuu/BAGA" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>X as Supervision: Contending with Depth Ambiguity in Unsupervised Monocular 3D Pose Estimation</b>
      <br>
      Yuchen Yang, Xuanyi Liu, Xing Gao, <strong>Zhihang Zhong</strong>, Xiao Sun
      <br>
      <em>arXiv</em>, 2024 <br>
      <a href="https://arxiv.org/abs/2411.13026" target="_blank">arXiv</a> /
      <a href="https://github.com/Charrrrrlie/X-as-Supervision" target="_blank">code</a>
    </td>
  </tr>

  <!-- <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>DIR: Retrieval-Augmented Image Captioning with Comprehensive Understanding</b>
      <br>
      Hao Wu, <strong>Zhihang Zhong<sup>‚Ä†</sup></strong>, Xiao Sun<sup>‚Ä†</sup>
      <br>
      <em>arXiv</em>, 2024 <br>
      <a href="https://arxiv.org/abs/2412.01115" target="_blank">arXiv</a>
    </td>
  </tr> -->

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Within the Dynamic Context: Inertia-aware 3D Human Modeling with<br>Pose Sequence</b>
      <br>
      Yutong Chen, Yifan Zhan, <strong>Zhihang Zhong<sup>‚Ä†</sup></strong>, Wei Wang, Xiao Sun<sup>‚Ä†</sup>, Yu Qiao,<br>Yinqiang Zheng
      <br>
      <em>ECCV</em>, 2024 <br>
      <a href="http://ai4sports.opengvlab.com/Dyco" target="_blank">project</a> / 
      <a href="https://arxiv.org/abs/2403.19160" target="_blank">arXiv</a> /
      <a href="https://github.com/Yifever20002/Dyco" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Clearer Frames, Anytime: Resolving Velocity Ambiguity in Video Frame Interpolation</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Gurunandan Krishnan,      
      Xiao Sun,
      Yu Qiao,
      Sizhuo Ma,
      Jian Wang
      <br>
      <em>ECCV</em>, 2024, <em style="color: red">Oral</em>
      <br>
      <a href="https://zzh-tech.github.io/InterpAny-Clearer/" target="_blank">project</a> /
      <a href="https://arxiv.org/abs/2311.08007v2" target="_blank">arXiv</a> /
      <a href="https://github.com/zzh-tech/InterpAny-Clearer" target="_blank">code</a>    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>KFD-NeRF: Rethinking Dynamic NeRF with Kalman Filter</b>
      <br>
      Yifan Zhan,
      Zhuoxiao Li,
      Muyao Niu,
      <strong>Zhihang Zhong</strong>,
      Shohei Nobuhara,
      Ko Nishino,
      <br>Yinqiang Zheng
      <br>
      <em>ECCV</em>, 2024
      <br>
      <a href="https://arxiv.org/abs/2407.13185" target="_blank">arXiv</a> /
      <a href="https://github.com/Yifever20002/KFD-NeRF" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>IQ-VFI: Implicit Quadratic Motion Estimation for Video Frame Interpolation</b>
      <br>
      Mengshun Hu,
      Kui Jiang,
      <strong>Zhihang Zhong</strong>,
      Zheng Wang,
      Yinqiang Zheng
      <br>
      <em>CVPR</em>, 2024
      <br>
      <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Hu_IQ-VFI_Implicit_Quadratic_Motion_Estimation_for_Video_Frame_Interpolation_CVPR_2024_paper.html" target="_blank">paper</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Fooling Polarization-based Vision using Locally Controllable Polarizing Projection</b>
      <br>
      Zhuoxiao Li,
      <strong>Zhihang Zhong</strong>,
      Shohei Nobuhara,
      Ko Nishino,
      Yinqiang Zheng
      <br>
      <em>CVPR</em>, 2024
      <br>
      <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Li_Fooling_Polarization-Based_Vision_using_Locally_Controllable_Polarizing_Projection_CVPR_2024_paper.html" target="_blank">paper</a> /
      <a href="https://arxiv.org/abs/2303.17890" target="_blank">arXiv</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>NIR-assisted Video Enhancement via Unpaired 24-hour Data </b>
      <br>
      Muyao Niu,
      <strong>Zhihang Zhong</strong>,
      Yinqiang Zheng
      <br>
      <em>ICCV</em>, 2023
      <br>
      <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Niu_NIR-assisted_Video_Enhancement_via_Unpaired_24-hour_Data_ICCV_2023_paper.html" target="_blank">paper</a> /
      <a href="https://github.com/MyNiuuu/NVEU" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Rethinking Video Frame Interpolation from Shutter Mode Induced Degradation</b>
      <br>
      Xiang Ji,
      Zhixiang Wang,
      <strong>Zhihang Zhong</strong>,
      Yinqiang Zheng
      <br>
      <em>ICCV</em>, 2023
      <br>
      <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Rethinking_Video_Frame_Interpolation_from_Shutter_Mode_Induced_Degradation_ICCV_2023_paper.html" target="_blank">paper</a> /
      <a href="https://github.com/jixiang2016/PMBNet" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>ClipCrop: Conditioned Cropping Driven by Vision-Language Model</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Mingxi Cheng,
      Zhirong Wu,
      Yuhui Yuan,
      Yinqiang Zheng,
      Ji Li, <br>
      Han Hu,
      Stephen Lin,
      Yoichi Sato,
      Imari Sato
      <br>
      <em>ICCV Workshops</em>, 2023
      <br>
      <a href="https://arxiv.org/abs/2211.11492" target="_blank">arXiv</a> /
      <a href="https://github.com/zzh-tech/ClipCrop" target="_blank">dataset</a>
    </td>
  </tr>  

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Event-guided Frame Interpolation and Dynamic Range Expansion <br> of Single Rolling Shutter Image</b>
      <br>
      Guixu Lin,
      Jin Han,
      Mingdeng Cao,
      <strong>Zhihang Zhong</strong>,
      Yinqiang Zheng
      <br>
      <em>ACM-MM</em>, 2023
      <br>
      <a href="https://dl.acm.org/doi/10.1145/3581783.3612093" target="_blank">paper</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Blur Interpolation Transformer for Real-World Motion from Blur</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Mingdeng Cao,
      Xiang Ji,
      Yinqiang Zheng,
      Imari Sato
      <br>
      <em>CVPR</em>, 2023
      <br>
      <a href="https://zzh-tech.github.io/BiT/" target="_blank">project</a> /
      <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Zhong_Blur_Interpolation_Transformer_for_Real-World_Motion_From_Blur_CVPR_2023_paper.html" target="_blank">paper</a> /
      <a href="https://arxiv.org/abs/2211.11423" target="_blank">arXiv</a> /
      <a href="https://github.com/zzh-tech/BiT" target="_blank">code</a> /
      <a href="https://zhuanlan.zhihu.com/p/614802509" target="_blank">zhihu</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Visibility Constrained Wide-band Illumination Spectrum Design <br> for Seeing-in-the-Dark</b>
      <br>
      Muyao Niu,
      Zhuoxiao Li,
      <strong>Zhihang Zhong</strong>,
      Yinqiang Zheng
      <br>
      <em>CVPR</em>, 2023
      <br>
      <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Niu_Visibility_Constrained_Wide-Band_Illumination_Spectrum_Design_for_Seeing-in-the-Dark_CVPR_2023_paper.html" target="_blank">paper</a> /
      <a href="https://arxiv.org/abs/2303.11642" target="_blank">arXiv</a> /
      <a href="https://github.com/MyNiuuu/VCSD" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Animation from Blur: Multi-modal Blur Decomposition with Motion Guidance</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Xiao Sun, 
      Zhirong Wu,
      Yinqiang Zheng,
      Stephen Lin,
      Imari Sato
      <br>
      <em>ECCV</em>, 2022
      <br>
      <a href="https://zzh-tech.github.io/Animation-from-Blur/" target="_blank">project</a> /
      <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/7210_ECCV_2022_paper.php" target="_blank">paper</a> /
      <a href="https://arxiv.org/abs/2207.10123" target="_blank">arXiv</a> / 
      <a href="https://github.com/zzh-tech/Animation-from-Blur" target="_blank">code</a> /
      <a href="https://zhuanlan.zhihu.com/p/614802509" target="_blank">zhihu</a>
    </td>
  </tr> 

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Bringing Rolling Shutter Images Alive with Dual Reversed Distortion</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
       Mingdeng Cao,
       Xiao Sun,
       Zhirong Wu,
       Zhongyi Zhou, <br>
       Yinqiang Zheng,
       Stephen Lin,
       Imari Sato
      <br>
      <em>ECCV</em>, 2022, <em style="color: red">Oral</em>
      <br>
      <a href="https://zzh-tech.github.io/Dual-Reversed-RS/" target="_blank">project</a> /
      <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/4547_ECCV_2022_paper.php" target="_blank">paper</a> /
      <a href="https://arxiv.org/abs/2203.06451" target="_blank">arXiv</a> / 
      <a href="https://github.com/zzh-tech/Dual-Reversed-RS" target="_blank">code</a>
    </td>
  </tr> 

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Efficient Video Deblurring Guided by Motion Magnitude</b>
      <br>
      Yusheng Wang, 
      Yunfan Lu, 
      Ye Gao, 
      Lin Wang, 
      <strong>Zhihang Zhong</strong>, <br>
      Yinqiang Zheng, 
      Atsushi Yamashita
      <br>
      <em>ECCV</em>, 2022
      <br>
      <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/5697_ECCV_2022_paper.php" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2207.13374" target="_blank">arXiv</a> / 
      <a href="https://github.com/sollynoay/MMP-RNN" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Towards Real-world Video Deblurring by Exploring Blur Formation Process</b>
      <br>
      Mingdeng Cao,
      <strong>Zhihang Zhong</strong>,
      Yanbo Fan,
      Jiahao Wang,
      Yong Zhang,
      Jue Wang, <br>
      Yujiu Yang,
      Yinqiang Zheng
      <br>
      <em>ECCV Workshops</em>, 2022
      <br>
      <a href="https://link.springer.com/chapter/10.1007/978-3-031-25063-7_20" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2208.13184" target="_blank">arXiv</a> / 
      <a href="https://github.com/ljzycmd/RAWBlur" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Learning Adaptive Warping for Real-World Rolling Shutter Correction</b>
      <br>
      Mingdeng Cao, 
      <strong>Zhihang Zhong</strong>, 
      Jiahao Wang, 
      Yinqiang Zheng, 
      Yujiu Yang
      <br>
      <em>CVPR</em>, 2022
      <br>
      <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Cao_Learning_Adaptive_Warping_for_Real-World_Rolling_Shutter_Correction_CVPR_2022_paper.html" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2204.13886" target="_blank">arXiv</a> / 
      <a href="https://github.com/ljzycmd/BSRSC" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Real-world Video Deblurring: A Benchmark Dataset and An EÔ¨Écient Recurrent <br>Neural Network</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Ye Gao,
      Yinqiang Zheng,
      Bo Zheng,
      Imari Sato
      <br>
      <em>International Journal of Computer Vision (IJCV)</em>, 2022  
      <br>
      <a href="https://link.springer.com/article/10.1007/s11263-022-01705-6" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2106.16028" target="_blank">arXiv</a> / 
      <a href="https://github.com/zzh-tech/ESTRNN" target="_blank">code</a>
    </td>
  </tr>    

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Towards Rolling Shutter Correction and Deblurring in Dynamic Scenes</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Yinqiang Zheng, 
      Imari Sato
      <br>
      <em>CVPR</em>, 2021
      <br>
      <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhong_Towards_Rolling_Shutter_Correction_and_Deblurring_in_Dynamic_Scenes_CVPR_2021_paper.html" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2104.01601" target="_blank">arXiv</a> / 
      <a href="https://github.com/zzh-tech/RSCD" target="_blank">code</a>
    </td>
  </tr>  

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Efficient Spatio-Temporal Recurrent Neural Network for Video Deblurring</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Ye Gao,
      Yinqiang Zheng,
      Bo Zheng
      <br>
      <em>ECCV</em>, 2020, <em style="color: red">Spotlight</em>
      <br>
      <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/5116_ECCV_2020_paper.php" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2106.16028" target="_blank">arXiv</a> / 
      <a href="https://github.com/zzh-tech/ESTRNN" target="_blank">code</a>
    </td>
  </tr>  

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Multistream Temporal Convolutional Network for Correct/Incorrect <br> Patient Transfer Action Detection using Body Sensor Network</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Chingszu Lin,
      Masako Kanai-Pak,
      Jukai Maeda,<br>
      Yasuko Kitajima,
      Mitsuhiro Nakamura,
      Noriaki Kuwahara,
      Taiki Ogata,
      Jun Ota
      <br>
      <em>IEEE Internet of Things Journal (IoTJ)</em>, 2021  
      <br>
      <a href="https://ieeexplore.ieee.org/document/9415629" target="_blank">paper</a> / 
      <a href="https://github.com/zzh-tech/Continuous-Action-Detection" target="_blank">code</a>  
    </td>
  </tr>  

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Development and Validation of Robot Patient Equipped with An Inertial Measurement Unit and Angular Position Sensors to Evaluate Transfer Skills of Nurses</b>
      <br>
      Chingszu Lin,
      Taiki Ogata,
      <strong>Zhihang Zhong</strong>,
      Masako Kanai-Pak,
      Jukai Maeda,
      Yasuko Kitajima,
      Mitsuhiro Nakamura,
      Noriaki Kuwahara,
      Jun Ota
      <br>
      <em>International Journal of Social Robotics (IJSR)</em>, 2021  
      <br>
      <a href="https://link.springer.com/article/10.1007/s12369-020-00673-6" target="_blank">paper</a>
    </td>
  </tr>  

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Multi-attention Deep Recurrent Neural Network for Nursing Action Evaluation <br>using Wearable Sensor</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Chingszu Lin,
      Taiki Ogata,
      Jun Ota
      <br>
      <em>IUI</em>, 2020
      <br>
      <a href="https://dl.acm.org/doi/abs/10.1145/3377325.3377530" target="_blank">paper</a>
    </td>
  </tr> 
</tbody>
</table>

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=500&t=tt&d=XXbPPAPR_Tykk65fLeKabiB6-HTFXjsQRAiCOlmsK7w&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>