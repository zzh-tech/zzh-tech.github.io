---
permalink: /
excerpt: "About"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

<br>

<font size="+0.2">
Hi, こんにちは, 你好 :-)
<br><br>

Zhihang Zhong is a researcher at <a href="https://www.shlab.org.cn/" target="_blank">Shanghai AI
Lab</a> (<a href="https://github.com/OpenGVLab" target="_blank">OpenGVLab</a>).<br>
In 2023, he received his Ph.D. degree in Computer Science from the University of Tokyo (UTokyo).<br>
In 2020, he received his M.E. degree in Precision Engineering from the UTokyo. <br>
In 2018, he received his B.E. degree in Mechatronics from Chu Kochen Honors College, Zhejiang University.<br>
<br>
Zhihang's current research interests include: <br>
<b><em>* 4D motion modeling</em></b><br>
<b><em>* AI for sports</em></b><br>
<em>image/video restoration and enhancement</em><br>
<br>
<b><em>We are looking for highly self-motivated students (Joint Ph.D., 联合培养博士), and interns!</em></b><br>
If you are interested, please email me with your CV and your published papers. <br>
(P.S. We have sufficient computing resources and remote is possible)
</font>

<br>
<img src="../files/ai4sports/badminton_unity_demo.gif" width="83%" height="83%"/>

## News

<font size="+0.2">
<details>
    <summary> [see more] <br>
    [2024.07] Glad to receive the 2023 Chinese Government Award for <a href="https://en.wikipedia.org/wiki/Chinese_government_award_for_outstanding_self-financed_students_abroad">Outstanding <br>Self-financed Students Abroad (Group B)</a>!<br>
    [2024.07] Three papers are accepted by ECCV 2024. <br>
    [2024.05] We release <a href="https://mp.weixin.qq.com/s/uBUfvuF09WBMnN_Fm_Ss7w">SportsStrat (浦动)</a> on CCTV5 in support of the 2024 Thomas & Uber Cups!<br>
    [2024.03] Glad to receive the <a href="https://www.i.u-tokyo.ac.jp/news/topics/2024/202403192381.shtml">Dean's Award for Academic Achievement</a> from the UTokyo! <br>
    [2024.02] Two papers are accepted by CVPR 2024. <br>
    [2023.12] I give a talk at <a href="https://mp.weixin.qq.com/s/9kYeSrJze2Ah7snSqPFLPg" target="_blank"> OpenMMLab</a> about temporal super-resolution. <br>
    </summary>
    [2023.11] Glad to release <a href="https://zzh-tech.github.io/InterpAny-Clearer/" target="_blank">InterpAny-Clearer</a> project! <br>
    [2023.07] Two papers are accepted by ICCV 2023. <br>
    [2023.07] One paper is accepted by ACM-MM 2023. <br>
    [2023.03] I am accepted to CVPR 2023's Doctoral Consortium. <br>
    [2023.02] Two papers are accepted by CVPR 2023. <br>
    [2022.10] I give a talk at <a
                href="https://mipi-challenge.org/#:~:text=Presenter%3A%20Zhihang%20Zhong%20(The%20University%20of%20Tokyo)"
                target="_blank">MIPI Workshop 2022</a>. <br>
    [2022.10] One paper is accepted by IJCV. <br>
    [2022.09] I become a JSPS「日本学術振興会」DC fellow! <br>
    [2022.07] Three papers (one Oral) are accepted by ECCV 2022! <br>
    [2022.04] I become a JEM intern at Microsoft. <br>
    [2022.03] One paper is accepted by CVPR 2022. <br>
    [2021.09] I become a research intern in the Visual Computing group at MSRA. <br>
    [2021.04] I become a IIW fellow「知能社会創造フェローシップ生」of UTokyo! <br>
    [2021.04] One paper is accepted by IoTJ. <br>
    [2021.02] One paper is accepted by CVPR 2021. <br>
    [2020.11] I become a MSRA D-CORE fellow! <br>
    [2020.09] I obtain my M.E. degree from UTokyo with an outstanding thesis award! <br>
    [2020.07] One paper (Spotlight) is accepted by ECCV 2020! <br>
    [2019.12] One paper is accepted by IUI 2020. <br>
</details>
</font>

## Publications

<head>
    <style>
    table,
    th,
    td {
        border: 0px solid darkgray;
    }
    </style><title></title>
</head>

<font size="+0.2">
<sup>*</sup> indicates first author, <sup>†</sup> indicates corresponding author
</font>

<table style="width:75%;border:0px;border-spacing:0px;margin-right:auto;margin-left:5px;">
<tbody>
  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Within the Dynamic Context: Inertia-aware 3D Human Modeling with<br>Pose Sequence</b>
      <br>
      Yutong Chen, Yifan Zhan, <strong>Zhihang Zhong<sup>†</sup></strong>, Wei Wang, Xiao Sun<sup>†</sup>, Yu Qiao,<br>Yinqiang Zheng
      <br>
      <em>ECCV</em>, 2024 <br>
      <a href="http://ai4sports.opengvlab.com/Dyco" target="_blank">project page</a> / 
      <a href="https://arxiv.org/abs/2403.19160" target="_blank">arXiv</a> /
      <a href="https://github.com/Yifever20002/Dyco" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Clearer Frames, Anytime: Resolving Velocity Ambiguity in Video Frame Interpolation</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Xiao Sun,
      Yu Qiao,
      Gurunandan Krishnan,
      Sizhuo Ma,
      Jian Wang
      <br>
      <em>ECCV</em>, 2024
      <br>
      <a href="https://zzh-tech.github.io/InterpAny-Clearer/" target="_blank">project page</a> /
      <a href="https://arxiv.org/abs/2311.08007" target="_blank">arXiv</a> /
      <a href="https://github.com/zzh-tech/InterpAny-Clearer" target="_blank">code</a> /
      <a href="http://ai4sports.opengvlab.com/interpany-clearer/" target="_blank">demo</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>KFD-NeRF: Rethinking Dynamic NeRF with Kalman Filter</b>
      <br>
      Yifan Zhan,
      Zhuoxiao Li,
      Muyao Niu,
      <strong>Zhihang Zhong</strong>,
      Shohei Nobuhara,
      Ko Nishino,
      Yinqiang Zheng
      <br>
      <em>ECCV</em>, 2024
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>IQ-VFI: Implicit Quadratic Motion Estimation for Video Frame Interpolation</b>
      <br>
      Mengshun Hu,
      Kui Jiang,
      <strong>Zhihang Zhong</strong>,
      Zheng Wang,
      Yinqiang Zheng
      <br>
      <em>CVPR</em>, 2024
      <br>
      <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Hu_IQ-VFI_Implicit_Quadratic_Motion_Estimation_for_Video_Frame_Interpolation_CVPR_2024_paper.html" target="_blank">paper</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Fooling Polarization-based Vision using Locally Controllable Polarizing Projection</b>
      <br>
      Zhuoxiao Li,
      <strong>Zhihang Zhong</strong>,
      Shohei Nobuhara,
      Ko Nishino,
      Yinqiang Zheng
      <br>
      <em>CVPR</em>, 2024
      <br>
      <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Li_Fooling_Polarization-Based_Vision_using_Locally_Controllable_Polarizing_Projection_CVPR_2024_paper.html" target="_blank">paper</a> /
      <a href="https://arxiv.org/abs/2303.17890" target="_blank">arXiv</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>DiffBody: Human Body Restoration by Imagining with Generative Diffusion Prior</b>
      <br>
      Yiming Zhang, Zhe Wang, Xinjie Li, Yunchen Yuan, Chengsong Zhang, Xiao Sun,<br><strong>Zhihang Zhong<sup>†</sup></strong>, Jian Wang<sup>†</sup>
      <br>
      <em>Under review</em>, 2024 <br>
      <a href="https://arxiv.org/abs/2404.03642" target="_blank">arXiv</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>NIR-assisted Low-light Video Enhancement Using Unpaired <br> 24-hour Data</b>
      <br>
      Muyao Niu,
      <strong>Zhihang Zhong</strong>,
      Yinqiang Zheng
      <br>
      <em>ICCV</em>, 2023
      <br>
      <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Niu_NIR-assisted_Video_Enhancement_via_Unpaired_24-hour_Data_ICCV_2023_paper.html" target="_blank">paper</a> /
      <a href="https://github.com/MyNiuuu/NVEU" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Rethinking Video Frame Interpolation from Shutter Mode Induced Degradation</b>
      <br>
      Xiang Ji,
      Zhixiang Wang,
      <strong>Zhihang Zhong</strong>,
      Yinqiang Zheng
      <br>
      <em>ICCV</em>, 2023
      <br>
      <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Rethinking_Video_Frame_Interpolation_from_Shutter_Mode_Induced_Degradation_ICCV_2023_paper.html" target="_blank">paper</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>ClipCrop: Conditioned Cropping Driven by Vision-Language Model</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Mingxi Cheng,
      Zhirong Wu,
      Yuhui Yuan,
      Yinqiang Zheng,
      Ji Li, <br>
      Han Hu,
      Stephen Lin,
      Yoichi Sato,
      Imari Sato
      <br>
      <em>ICCV Workshops</em>, 2023
      <br>
      <a href="https://arxiv.org/abs/2211.11492" target="_blank">arXiv</a>
    </td>
  </tr>  

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Event-guided Frame Interpolation and Dynamic Range Expansion <br> of Single Rolling Shutter Image</b>
      <br>
      Guixu Lin,
      Jin Han,
      Mingdeng Cao,
      <strong>Zhihang Zhong</strong>,
      Yinqiang Zheng
      <br>
      <em>ACM-MM</em>, 2023
      <br>
      <a href="https://dl.acm.org/doi/10.1145/3581783.3612093" target="_blank">paper</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Blur Interpolation Transformer for Real-World Motion from Blur</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Mingdeng Cao,
      Xiang Ji,
      Yinqiang Zheng,
      Imari Sato
      <br>
      <em>CVPR</em>, 2023
      <br>
      <a href="https://zzh-tech.github.io/BiT/" target="_blank">project page</a> /
      <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Zhong_Blur_Interpolation_Transformer_for_Real-World_Motion_From_Blur_CVPR_2023_paper.html" target="_blank">paper</a> /
      <a href="https://arxiv.org/abs/2211.11423" target="_blank">arXiv</a> /
      <a href="https://github.com/zzh-tech/BiT" target="_blank">code</a> /
      <a href="https://zhuanlan.zhihu.com/p/614802509" target="_blank">zhihu</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Visibility Constrained Wide-band Illumination Spectrum Design <br> for Seeing-in-the-Dark</b>
      <br>
      Muyao Niu,
      Zhuoxiao Li,
      <strong>Zhihang Zhong</strong>,
      Yinqiang Zheng
      <br>
      <em>CVPR</em>, 2023
      <br>
      <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Niu_Visibility_Constrained_Wide-Band_Illumination_Spectrum_Design_for_Seeing-in-the-Dark_CVPR_2023_paper.html" target="_blank">paper</a> /
      <a href="https://arxiv.org/abs/2303.11642" target="_blank">arXiv</a> /
      <a href="https://github.com/MyNiuuu/VCSD" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Animation from Blur: Multi-modal Blur Decomposition with <br> Motion Guidance</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Xiao Sun, 
      Zhirong Wu,
      Yinqiang Zheng,
      Stephen Lin,
      Imari Sato
      <br>
      <em>ECCV</em>, 2022
      <br>
      <a href="https://zzh-tech.github.io/Animation-from-Blur/" target="_blank">project page</a> /
      <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/7210_ECCV_2022_paper.php" target="_blank">paper</a> /
      <a href="https://arxiv.org/abs/2207.10123" target="_blank">arXiv</a> / 
      <a href="https://github.com/zzh-tech/Animation-from-Blur" target="_blank">code</a> /
      <a href="https://zhuanlan.zhihu.com/p/614802509" target="_blank">zhihu</a>
    </td>
  </tr> 

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Bringing Rolling Shutter Images Alive with Dual Reversed Distortion</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
       Mingdeng Cao,
       Xiao Sun,
       Zhirong Wu,
       Zhongyi Zhou, <br>
       Yinqiang Zheng,
       Stephen Lin,
       Imari Sato
      <br>
      <em>ECCV</em>, 2022, <em style="color: red">Oral (top 2.7%)</em>
      <br>
      <a href="https://zzh-tech.github.io/Dual-Reversed-RS/" target="_blank">project page</a> /
      <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/4547_ECCV_2022_paper.php" target="_blank">paper</a> /
      <a href="https://arxiv.org/abs/2203.06451" target="_blank">arXiv</a> / 
      <a href="https://github.com/zzh-tech/Dual-Reversed-RS" target="_blank">code</a>
    </td>
  </tr> 

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Efficient Video Deblurring Guided by Motion Magnitude</b>
      <br>
      Yusheng Wang, 
      Yunfan Lu, 
      Ye Gao, 
      Lin Wang, 
      <strong>Zhihang Zhong</strong>, <br>
      Yinqiang Zheng, 
      Atsushi Yamashita
      <br>
      <em>ECCV</em>, 2022
      <br>
      <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/5697_ECCV_2022_paper.php" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2207.13374" target="_blank">arXiv</a> / 
      <a href="https://github.com/sollynoay/MMP-RNN" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Towards real-world video deblurring by exploring blur formation process</b>
      <br>
      Mingdeng Cao,
      <strong>Zhihang Zhong</strong>,
      Yanbo Fan,
      Jiahao Wang,
      Yong Zhang,
      Jue Wang, <br>
      Yujiu Yang,
      Yinqiang Zheng
      <br>
      <em>ECCV Workshops</em>, 2022
      <br>
      <a href="https://link.springer.com/chapter/10.1007/978-3-031-25063-7_20" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2208.13184" target="_blank">arXiv</a> / 
      <a href="https://github.com/ljzycmd/RAWBlur" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Learning Adaptive Warping for Real-World Rolling Shutter Correction</b>
      <br>
      Mingdeng Cao, 
      <strong>Zhihang Zhong</strong>, 
      Jiahao Wang, 
      Yinqiang Zheng, 
      Yujiu Yang
      <br>
      <em>CVPR</em>, 2022
      <br>
      <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Cao_Learning_Adaptive_Warping_for_Real-World_Rolling_Shutter_Correction_CVPR_2022_paper.html" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2204.13886" target="_blank">arXiv</a> / 
      <a href="https://github.com/ljzycmd/BSRSC" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Real-world Video Deblurring: A Benchmark Dataset and An Eﬃcient <br> Recurrent Neural Network</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Ye Gao,
      Yinqiang Zheng,
      Bo Zheng,
      Imari Sato
      <br>
      <em>International Journal of Computer Vision (IJCV)</em>, 2022  
      <br>
      <a href="https://link.springer.com/article/10.1007/s11263-022-01705-6" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2106.16028" target="_blank">arXiv</a> / 
      <a href="https://github.com/zzh-tech/ESTRNN" target="_blank">code</a>
    </td>
  </tr>    

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Towards Rolling Shutter Correction and Deblurring in Dynamic Scenes</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Yinqiang Zheng, 
      Imari Sato
      <br>
      <em>CVPR</em>, 2021
      <br>
      <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhong_Towards_Rolling_Shutter_Correction_and_Deblurring_in_Dynamic_Scenes_CVPR_2021_paper.html" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2104.01601" target="_blank">arXiv</a> / 
      <a href="https://github.com/zzh-tech/RSCD" target="_blank">code</a>
    </td>
  </tr>  

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Efficient Spatio-Temporal Recurrent Neural Network for Video Deblurring</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Ye Gao,
      Yinqiang Zheng,
      Bo Zheng
      <br>
      <em>ECCV</em>, 2020, <em style="color: red">Spotlight (top 5.0%)</em>
      <br>
      <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/5116_ECCV_2020_paper.php" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2106.16028" target="_blank">arXiv</a> / 
      <a href="https://github.com/zzh-tech/ESTRNN" target="_blank">code</a>
    </td>
  </tr>  

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Multistream Temporal Convolutional Network for Correct/Incorrect <br> Patient Transfer Action Detection Using Body Sensor Network</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Chingszu Lin,
      Masako Kanai-Pak,
      Jukai Maeda,
      Yasuko Kitajima,
      Mitsuhiro Nakamura,
      Noriaki Kuwahara,
      Taiki Ogata,
      Jun Ota
      <br>
      <em>IEEE Internet of Things Journal (IoTJ)</em>, 2021  
      <br>
      <a href="https://ieeexplore.ieee.org/document/9415629" target="_blank">paper</a> / 
      <a href="https://github.com/zzh-tech/Continuous-Action-Detection" target="_blank">code</a>  
    </td>
  </tr>  

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Development and validation of robot patient equipped with an inertial measurement unit and angular position sensors to evaluate transfer <br> skills of nurses</b>
      <br>
      Chingszu Lin,
      Taiki Ogata,
      <strong>Zhihang Zhong</strong>,
      Masako Kanai-Pak,
      Jukai Maeda,
      Yasuko Kitajima,
      Mitsuhiro Nakamura,
      Noriaki Kuwahara,
      Jun Ota
      <br>
      <em>International Journal of Social Robotics (IJSR)</em>, 2021  
      <br>
      <a href="https://link.springer.com/article/10.1007/s12369-020-00673-6" target="_blank">paper</a>
    </td>
  </tr>  

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Multi-attention deep recurrent neural network for nursing action <br> evaluation using wearable sensor</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Chingszu Lin,
      Taiki Ogata,
      Jun Ota
      <br>
      <em>IUI</em>, 2020
      <br>
      <a href="https://dl.acm.org/doi/abs/10.1145/3377325.3377530" target="_blank">paper</a>
    </td>
  </tr> 
</tbody>
</table>

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=500&t=tt&d=XXbPPAPR_Tykk65fLeKabiB6-HTFXjsQRAiCOlmsK7w&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>