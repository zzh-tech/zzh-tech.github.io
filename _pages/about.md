---
permalink: /
excerpt: "About"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

<br>

<font size="+0.2">
Hi, こんにちは, 你好 :-)
<br><br>

Zhihang Zhong is a researcher at <a href="https://www.shlab.org.cn/" target="_blank">Shanghai AI
Laboratory</a>.<br>
In 2023, he received his Ph.D. degree in Computer Science from the University of Tokyo (UTokyo).<br>
In 2020, he received his M.E. degree in Precision Engineering from the UTokyo. <br>
In 2018, he received his B.E. degree in Mechatronics from Chu Kochen Honors College, Zhejiang University.<br>
<br>
Zhihang's current research interests include: <br>
<b><em>* Spatial Intelligence</em></b><br>
<b><em>* Neural Rendering</em></b><br>
<em>* Computational Photography</em><br>
<br>
<em>We are looking for<br>
<b>(1) research interns in 3D/4D Peception, Generation and Editing;</b><br>
<b>(2) research interns in Spatial Intelligence based on Multimodal Large Models;</b><br>
(3) remote collaborators with relevant research interests.<br>
If you are interested, please email me ( zhongzhihang [at] pjlab.org.cn ) with your Resume.</em><br>
</font>

<br>
<img src="../files/ai4sports/badminton_unity_demo.gif" width="83%" height="83%"/>

## News

<font size="+0.2">
<details>
    <summary> [see more] <br>
    [2025.06] Three papers are accepted to ICCV 2025. <br>
    [2025.02] <a href="https://github.com/kaikai23/maskgaussian" target="_blank">MaskGaussian</a> is accepted to CVPR 2025. <br>
    [2024.08] Our <a href="https://mp.weixin.qq.com/s/dEAAvAupqjAMHczwTUCkhQ?version=4.1.28.6010&platform=win&nwr_flag=1#wechat_redirect" target="_blank">SportsStrat (浦动) empowers the 2024 Paris Olympics</a>!<br>
    [2024.07] Glad to receive the 2023 <a href="https://en.wikipedia.org/wiki/Chinese_government_award_for_outstanding_self-financed_students_abroad" target="_blank">Chinese Government Award for Outstanding <br>Self-financed Students Abroad (Group B, Global Top 50)</a>!<br>
    [2024.07] Three papers (one Oral) are accepted to ECCV 2024! <br>
    [2024.05] We release <a href="https://mp.weixin.qq.com/s/uBUfvuF09WBMnN_Fm_Ss7w" target="_blank">SportsStrat (浦动) on CCTV5 in support of the 2024 Thomas & Uber Cups</a>!<br>
    </summary>    
    [2024.03] Glad to receive the <a href="https://www.i.u-tokyo.ac.jp/news/topics/2024/202403192381.shtml" target="_blank">Dean's Award for Academic Achievement</a> from the UTokyo! <br>
    [2024.02] Two papers are accepted to CVPR 2024. <br>
    [2023.12] I give a talk at <a href="https://mp.weixin.qq.com/s/9kYeSrJze2Ah7snSqPFLPg" target="_blank"> OpenMMLab</a> about temporal super-resolution. <br>
    [2023.11] Glad to release <a href="https://zzh-tech.github.io/InterpAny-Clearer/" target="_blank">InterpAny-Clearer</a> project! <br>
    [2023.07] Two papers are accepted to ICCV 2023. <br>
    [2023.07] One paper is accepted to ACM-MM 2023. <br>
    [2023.03] I am accepted to CVPR 2023's Doctoral Consortium. <br>
    [2023.02] Two papers are accepted to CVPR 2023. <br>
    [2022.10] I give a talk at <a
                href="https://mipi-challenge.org/#:~:text=Presenter%3A%20Zhihang%20Zhong%20(The%20University%20of%20Tokyo)"
                target="_blank">MIPI Workshop 2022</a>. <br>
    [2022.10] One paper is accepted to IJCV. <br>
    [2022.09] I become a JSPS「日本学術振興会」DC fellow! <br>
    [2022.07] Three papers (one Oral) are accepted to ECCV 2022! <br>
    [2022.04] I become a JEM intern at Microsoft. <br>
    [2022.03] One paper is accepted to CVPR 2022. <br>
    [2021.09] I become a research intern in the Visual Computing group at MSRA. <br>
    [2021.04] I become a IIW fellow「知能社会創造フェローシップ生」of UTokyo! <br>
    [2021.04] One paper is accepted to IoTJ. <br>
    [2021.02] One paper is accepted to CVPR 2021. <br>
    [2020.11] I become a MSRA D-CORE fellow! <br>
    [2020.09] I obtain my M.E. degree from UTokyo with an outstanding thesis award! <br>
    [2020.07] One paper (Spotlight) is accepted to ECCV 2020! <br>
    [2019.12] One paper is accepted to IUI 2020. <br>
</details>
</font>

## Publications

<head>
    <style>
    table,
    th,
    td {
        border: 0px solid darkgray;
    }
    </style><title></title>
</head>

<font size="+0.2">
<sup>*</sup> indicates first author, <sup>†</sup> indicates corresponding author
</font>

<table style="width:75%;border:0px;border-spacing:0px;margin-right:auto;margin-left:5px;">
<tbody>
  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>CityGS-X: A Scalable Architecture for Efficient and Geometrically Accurate Large-Scale Scene Reconstruction</b>
      <br>
      Yuanyuan Gao, Hao Li, Jiaqi Chen, Zhengyu Zou, <strong>Zhihang Zhong<sup>†</sup></strong>, Dingwen Zhang<sup>†</sup>,<br>Xiao Sun, Junwei Han
      <br>
      <em>ICCV</em>, 2025 <br>
      <a href="https://lifuguan.github.io/CityGS-X/" target="_blank">project page</a> /
      <a href="https://arxiv.org/abs/2503.23044" target="_blank">arXiv</a> /
      <a href="https://github.com/gyy456/CityGS-X" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Sequential Gaussian Avatars with Hierarchical Motion Context</b>
      <br>
      Wangze Xu, Yifan Zhan, <strong>Zhihang Zhong<sup>†</sup></strong>, Xiao Sun<sup>†</sup>
      <br>
      <em>ICCV</em>, 2025 <br>
      <a href="https://zezeaaa.github.io/projects/SeqAvatar/" target="_blank">project page</a> /
      <a href="https://arxiv.org/abs/2411.16768" target="_blank">arXiv</a> /
      <a href="https://github.com/zezeaaa/SeqAvatar" target="_blank">code</a>
    </td>
  </tr>
  
  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Towards Explicit Exoskeleton for the Reconstruction of Complicated 3D Human Avatars</b>
      <br>
      Yifan Zhan, Qingtian Zhu, Muyao Niu, Mingze Ma, Jiancheng Zhao, <strong>Zhihang Zhong<sup>†</sup></strong>, <br>Xiao Sun<sup>†</sup>, Yu Qiao, Yinqiang Zheng
      <br>
      <em>ICCV</em>, 2025 <br>
      <a href="https://arxiv.org/abs/2410.08082" target="_blank">arXiv</a> /
      <a href="https://github.com/Yifever20002/ToMiE" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks</b>
      <br>
      Yifei Liu, <strong>Zhihang Zhong<sup>†</sup></strong>, Yifan Zhan, Sheng Xu, Xiao Sun<sup>†</sup>
      <br>
      <em>CVPR</em>, 2025 <br>
      <a href="https://maskgaussian.github.io/" target="_blank">project page</a> /
      <a href="https://arxiv.org/abs/2412.20522" target="_blank">arXiv</a> /
      <a href="https://github.com/kaikai23/maskgaussian" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>DiffBody: Human Body Image Restoration with Generative Diffusion Prior</b>
      <br>
      Yiming Zhang, Zhe Wang, Sizhuo Ma, Xinjie Li, Jian Ren, <strong>Zhihang Zhong<sup>†</sup></strong>, Jian Wang<sup>†</sup>
      <br>
      <em>ICCP</em>, 2025 <br>
      <a href="https://arxiv.org/abs/2404.03642" target="_blank">arXiv</a>
    </td>
  </tr>
  
  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>AniCrafter: Customizing Realistic Human-Centric Animation via Avatar-Background Conditioning in Video Diffusion Models</b>
      <br>
      Muyao Niu, Mingdeng Cao, Yifan Zhan, Qingtian Zhu, Mingze Ma, Jiancheng Zhao, Yanhong Zeng, <strong>Zhihang Zhong<sup>†</sup></strong>, Xiao Sun<sup>†</sup>, Yinqiang Zheng
      <br>
      <em>arxiv</em>, 2025 <br>
      <a href="https://myniuuu.github.io/AniCrafter/" target="_blank">project page</a> /
      <a href="https://www.arxiv.org/abs/2505.20255" target="_blank">arXiv</a> /
      <a href="https://github.com/MyNiuuu/AniCrafter" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>R<sup>3</sup>-Avatar: Record and Retrieve Temporal Codebook for Reconstructing Photorealistic Human Avatars</b>
      <br>
      Yifan Zhan, Wangze Xu, Qingtian Zhu, Muyao Niu, Mingze Ma, Yifei Liu, <strong>Zhihang Zhong<sup>†</sup></strong>, <br>Xiao Sun<sup>†</sup>, Yinqiang Zheng
      <br>
      <em>arxiv</em>, 2025 <br>
      <a href="https://arxiv.org/abs/2503.12751" target="_blank">arXiv</a> /
      <a href="https://github.com/Yifever20002/R3Avatars" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>SGA-INTERACT: A 3D Skeleton-based Benchmark for Group Activity Understanding in Modern Basketball Tactic</b>
      <br>
      Yuchen Yang, Wei Wang, Yifei Liu, Linfeng Dong, Hao Wu, Mingxin Zhang, <strong>Zhihang Zhong<sup>†</sup></strong>, Xiao Sun<sup>†</sup>
      <br>
      <em>arxiv</em>, 2025 <br>
      <a href="https://arxiv.org/abs/2503.06522" target="_blank">arXiv</a> /
      <a href="https://github.com/Charrrrrlie/SGA-INTERACT?tab=readme-ov-file" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Disambiguation for Video Frame Interpolation</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Yiming Zhang,
      Wei Wang,
      Xiao Sun,
      Yu Qiao,
      Gurunandan Krishnan,
      Sizhuo Ma,
      Jian Wang
      <br>
      <em>arxiv</em>, 2025
      <br>
      <a href="https://arxiv.org/abs/2311.08007v3" target="_blank">arXiv</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Bundle Adjusted Gaussian Avatars Deblurring</b>
      <br>
      Muyao Niu, Yifan Zhan, Qingtian Zhu, Zhuoxiao Li, Wei Wang, <strong>Zhihang Zhong<sup>†</sup></strong>,<br>Xiao Sun<sup>†</sup>, Yinqiang Zheng
      <br>
      <em>arXiv</em>, 2024 <br>
      <a href="https://www.arxiv.org/abs/2411.16758" target="_blank">arXiv</a> /
      <a href="https://github.com/MyNiuuu/BAGA" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>X as Supervision: Contending with Depth Ambiguity in Unsupervised Monocular 3D Pose Estimation</b>
      <br>
      Yuchen Yang, Xuanyi Liu, Xing Gao, <strong>Zhihang Zhong</strong>, Xiao Sun
      <br>
      <em>arXiv</em>, 2024 <br>
      <a href="https://arxiv.org/abs/2411.13026" target="_blank">arXiv</a> /
      <a href="https://github.com/Charrrrrlie/X-as-Supervision" target="_blank">code</a>
    </td>
  </tr>

  <!-- <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>DIR: Retrieval-Augmented Image Captioning with Comprehensive Understanding</b>
      <br>
      Hao Wu, <strong>Zhihang Zhong<sup>†</sup></strong>, Xiao Sun<sup>†</sup>
      <br>
      <em>arXiv</em>, 2024 <br>
      <a href="https://arxiv.org/abs/2412.01115" target="_blank">arXiv</a>
    </td>
  </tr> -->

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Within the Dynamic Context: Inertia-aware 3D Human Modeling with<br>Pose Sequence</b>
      <br>
      Yutong Chen, Yifan Zhan, <strong>Zhihang Zhong<sup>†</sup></strong>, Wei Wang, Xiao Sun<sup>†</sup>, Yu Qiao,<br>Yinqiang Zheng
      <br>
      <em>ECCV</em>, 2024 <br>
      <a href="http://ai4sports.opengvlab.com/Dyco" target="_blank">project page</a> / 
      <a href="https://arxiv.org/abs/2403.19160" target="_blank">arXiv</a> /
      <a href="https://github.com/Yifever20002/Dyco" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Clearer Frames, Anytime: Resolving Velocity Ambiguity in Video Frame Interpolation</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Gurunandan Krishnan,      
      Xiao Sun,
      Yu Qiao,
      Sizhuo Ma,
      Jian Wang
      <br>
      <em>ECCV</em>, 2024, <em style="color: red">Oral</em>
      <br>
      <a href="https://zzh-tech.github.io/InterpAny-Clearer/" target="_blank">project page</a> /
      <a href="https://arxiv.org/abs/2311.08007v2" target="_blank">arXiv</a> /
      <a href="https://github.com/zzh-tech/InterpAny-Clearer" target="_blank">code</a> /
      <a href="http://ai4sports.opengvlab.com/interpany-clearer/" target="_blank">demo</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>KFD-NeRF: Rethinking Dynamic NeRF with Kalman Filter</b>
      <br>
      Yifan Zhan,
      Zhuoxiao Li,
      Muyao Niu,
      <strong>Zhihang Zhong</strong>,
      Shohei Nobuhara,
      Ko Nishino,
      <br>Yinqiang Zheng
      <br>
      <em>ECCV</em>, 2024
      <br>
      <a href="https://arxiv.org/abs/2407.13185" target="_blank">arXiv</a> /
      <a href="https://github.com/Yifever20002/KFD-NeRF" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>IQ-VFI: Implicit Quadratic Motion Estimation for Video Frame Interpolation</b>
      <br>
      Mengshun Hu,
      Kui Jiang,
      <strong>Zhihang Zhong</strong>,
      Zheng Wang,
      Yinqiang Zheng
      <br>
      <em>CVPR</em>, 2024
      <br>
      <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Hu_IQ-VFI_Implicit_Quadratic_Motion_Estimation_for_Video_Frame_Interpolation_CVPR_2024_paper.html" target="_blank">paper</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Fooling Polarization-based Vision using Locally Controllable Polarizing Projection</b>
      <br>
      Zhuoxiao Li,
      <strong>Zhihang Zhong</strong>,
      Shohei Nobuhara,
      Ko Nishino,
      Yinqiang Zheng
      <br>
      <em>CVPR</em>, 2024
      <br>
      <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Li_Fooling_Polarization-Based_Vision_using_Locally_Controllable_Polarizing_Projection_CVPR_2024_paper.html" target="_blank">paper</a> /
      <a href="https://arxiv.org/abs/2303.17890" target="_blank">arXiv</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>NIR-assisted Video Enhancement via Unpaired 24-hour Data </b>
      <br>
      Muyao Niu,
      <strong>Zhihang Zhong</strong>,
      Yinqiang Zheng
      <br>
      <em>ICCV</em>, 2023
      <br>
      <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Niu_NIR-assisted_Video_Enhancement_via_Unpaired_24-hour_Data_ICCV_2023_paper.html" target="_blank">paper</a> /
      <a href="https://github.com/MyNiuuu/NVEU" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Rethinking Video Frame Interpolation from Shutter Mode Induced Degradation</b>
      <br>
      Xiang Ji,
      Zhixiang Wang,
      <strong>Zhihang Zhong</strong>,
      Yinqiang Zheng
      <br>
      <em>ICCV</em>, 2023
      <br>
      <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Rethinking_Video_Frame_Interpolation_from_Shutter_Mode_Induced_Degradation_ICCV_2023_paper.html" target="_blank">paper</a> /
      <a href="https://github.com/jixiang2016/PMBNet" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>ClipCrop: Conditioned Cropping Driven by Vision-Language Model</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Mingxi Cheng,
      Zhirong Wu,
      Yuhui Yuan,
      Yinqiang Zheng,
      Ji Li, <br>
      Han Hu,
      Stephen Lin,
      Yoichi Sato,
      Imari Sato
      <br>
      <em>ICCV Workshops</em>, 2023
      <br>
      <a href="https://arxiv.org/abs/2211.11492" target="_blank">arXiv</a> /
      <a href="https://github.com/zzh-tech/ClipCrop" target="_blank">dataset</a>
    </td>
  </tr>  

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
      <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Event-guided Frame Interpolation and Dynamic Range Expansion <br> of Single Rolling Shutter Image</b>
      <br>
      Guixu Lin,
      Jin Han,
      Mingdeng Cao,
      <strong>Zhihang Zhong</strong>,
      Yinqiang Zheng
      <br>
      <em>ACM-MM</em>, 2023
      <br>
      <a href="https://dl.acm.org/doi/10.1145/3581783.3612093" target="_blank">paper</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Blur Interpolation Transformer for Real-World Motion from Blur</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Mingdeng Cao,
      Xiang Ji,
      Yinqiang Zheng,
      Imari Sato
      <br>
      <em>CVPR</em>, 2023
      <br>
      <a href="https://zzh-tech.github.io/BiT/" target="_blank">project page</a> /
      <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Zhong_Blur_Interpolation_Transformer_for_Real-World_Motion_From_Blur_CVPR_2023_paper.html" target="_blank">paper</a> /
      <a href="https://arxiv.org/abs/2211.11423" target="_blank">arXiv</a> /
      <a href="https://github.com/zzh-tech/BiT" target="_blank">code</a> /
      <a href="https://zhuanlan.zhihu.com/p/614802509" target="_blank">zhihu</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Visibility Constrained Wide-band Illumination Spectrum Design <br> for Seeing-in-the-Dark</b>
      <br>
      Muyao Niu,
      Zhuoxiao Li,
      <strong>Zhihang Zhong</strong>,
      Yinqiang Zheng
      <br>
      <em>CVPR</em>, 2023
      <br>
      <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Niu_Visibility_Constrained_Wide-Band_Illumination_Spectrum_Design_for_Seeing-in-the-Dark_CVPR_2023_paper.html" target="_blank">paper</a> /
      <a href="https://arxiv.org/abs/2303.11642" target="_blank">arXiv</a> /
      <a href="https://github.com/MyNiuuu/VCSD" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Animation from Blur: Multi-modal Blur Decomposition with Motion Guidance</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Xiao Sun, 
      Zhirong Wu,
      Yinqiang Zheng,
      Stephen Lin,
      Imari Sato
      <br>
      <em>ECCV</em>, 2022
      <br>
      <a href="https://zzh-tech.github.io/Animation-from-Blur/" target="_blank">project page</a> /
      <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/7210_ECCV_2022_paper.php" target="_blank">paper</a> /
      <a href="https://arxiv.org/abs/2207.10123" target="_blank">arXiv</a> / 
      <a href="https://github.com/zzh-tech/Animation-from-Blur" target="_blank">code</a> /
      <a href="https://zhuanlan.zhihu.com/p/614802509" target="_blank">zhihu</a>
    </td>
  </tr> 

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Bringing Rolling Shutter Images Alive with Dual Reversed Distortion</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
       Mingdeng Cao,
       Xiao Sun,
       Zhirong Wu,
       Zhongyi Zhou, <br>
       Yinqiang Zheng,
       Stephen Lin,
       Imari Sato
      <br>
      <em>ECCV</em>, 2022, <em style="color: red">Oral</em>
      <br>
      <a href="https://zzh-tech.github.io/Dual-Reversed-RS/" target="_blank">project page</a> /
      <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/4547_ECCV_2022_paper.php" target="_blank">paper</a> /
      <a href="https://arxiv.org/abs/2203.06451" target="_blank">arXiv</a> / 
      <a href="https://github.com/zzh-tech/Dual-Reversed-RS" target="_blank">code</a>
    </td>
  </tr> 

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Efficient Video Deblurring Guided by Motion Magnitude</b>
      <br>
      Yusheng Wang, 
      Yunfan Lu, 
      Ye Gao, 
      Lin Wang, 
      <strong>Zhihang Zhong</strong>, <br>
      Yinqiang Zheng, 
      Atsushi Yamashita
      <br>
      <em>ECCV</em>, 2022
      <br>
      <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/5697_ECCV_2022_paper.php" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2207.13374" target="_blank">arXiv</a> / 
      <a href="https://github.com/sollynoay/MMP-RNN" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Towards Real-world Video Deblurring by Exploring Blur Formation Process</b>
      <br>
      Mingdeng Cao,
      <strong>Zhihang Zhong</strong>,
      Yanbo Fan,
      Jiahao Wang,
      Yong Zhang,
      Jue Wang, <br>
      Yujiu Yang,
      Yinqiang Zheng
      <br>
      <em>ECCV Workshops</em>, 2022
      <br>
      <a href="https://link.springer.com/chapter/10.1007/978-3-031-25063-7_20" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2208.13184" target="_blank">arXiv</a> / 
      <a href="https://github.com/ljzycmd/RAWBlur" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Learning Adaptive Warping for Real-World Rolling Shutter Correction</b>
      <br>
      Mingdeng Cao, 
      <strong>Zhihang Zhong</strong>, 
      Jiahao Wang, 
      Yinqiang Zheng, 
      Yujiu Yang
      <br>
      <em>CVPR</em>, 2022
      <br>
      <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Cao_Learning_Adaptive_Warping_for_Real-World_Rolling_Shutter_Correction_CVPR_2022_paper.html" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2204.13886" target="_blank">arXiv</a> / 
      <a href="https://github.com/ljzycmd/BSRSC" target="_blank">code</a>
    </td>
  </tr>

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Real-world Video Deblurring: A Benchmark Dataset and An Eﬃcient Recurrent <br>Neural Network</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Ye Gao,
      Yinqiang Zheng,
      Bo Zheng,
      Imari Sato
      <br>
      <em>International Journal of Computer Vision (IJCV)</em>, 2022  
      <br>
      <a href="https://link.springer.com/article/10.1007/s11263-022-01705-6" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2106.16028" target="_blank">arXiv</a> / 
      <a href="https://github.com/zzh-tech/ESTRNN" target="_blank">code</a>
    </td>
  </tr>    

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Towards Rolling Shutter Correction and Deblurring in Dynamic Scenes</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Yinqiang Zheng, 
      Imari Sato
      <br>
      <em>CVPR</em>, 2021
      <br>
      <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhong_Towards_Rolling_Shutter_Correction_and_Deblurring_in_Dynamic_Scenes_CVPR_2021_paper.html" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2104.01601" target="_blank">arXiv</a> / 
      <a href="https://github.com/zzh-tech/RSCD" target="_blank">code</a>
    </td>
  </tr>  

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Efficient Spatio-Temporal Recurrent Neural Network for Video Deblurring</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Ye Gao,
      Yinqiang Zheng,
      Bo Zheng
      <br>
      <em>ECCV</em>, 2020, <em style="color: red">Spotlight</em>
      <br>
      <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/5116_ECCV_2020_paper.php" target="_blank">paper</a> / 
      <a href="https://arxiv.org/abs/2106.16028" target="_blank">arXiv</a> / 
      <a href="https://github.com/zzh-tech/ESTRNN" target="_blank">code</a>
    </td>
  </tr>  

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Multistream Temporal Convolutional Network for Correct/Incorrect <br> Patient Transfer Action Detection using Body Sensor Network</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Chingszu Lin,
      Masako Kanai-Pak,
      Jukai Maeda,<br>
      Yasuko Kitajima,
      Mitsuhiro Nakamura,
      Noriaki Kuwahara,
      Taiki Ogata,
      Jun Ota
      <br>
      <em>IEEE Internet of Things Journal (IoTJ)</em>, 2021  
      <br>
      <a href="https://ieeexplore.ieee.org/document/9415629" target="_blank">paper</a> / 
      <a href="https://github.com/zzh-tech/Continuous-Action-Detection" target="_blank">code</a>  
    </td>
  </tr>  

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Development and Validation of Robot Patient Equipped with An Inertial Measurement Unit and Angular Position Sensors to Evaluate Transfer Skills of Nurses</b>
      <br>
      Chingszu Lin,
      Taiki Ogata,
      <strong>Zhihang Zhong</strong>,
      Masako Kanai-Pak,
      Jukai Maeda,
      Yasuko Kitajima,
      Mitsuhiro Nakamura,
      Noriaki Kuwahara,
      Jun Ota
      <br>
      <em>International Journal of Social Robotics (IJSR)</em>, 2021  
      <br>
      <a href="https://link.springer.com/article/10.1007/s12369-020-00673-6" target="_blank">paper</a>
    </td>
  </tr>  

  <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
    <td style="padding:10px;width:70%;vertical-align:middle">
        <b>Multi-attention Deep Recurrent Neural Network for Nursing Action Evaluation <br>using Wearable Sensor</b>
      <br>
      <strong>Zhihang Zhong<sup>*</sup></strong>,
      Chingszu Lin,
      Taiki Ogata,
      Jun Ota
      <br>
      <em>IUI</em>, 2020
      <br>
      <a href="https://dl.acm.org/doi/abs/10.1145/3377325.3377530" target="_blank">paper</a>
    </td>
  </tr> 
</tbody>
</table>

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=500&t=tt&d=XXbPPAPR_Tykk65fLeKabiB6-HTFXjsQRAiCOlmsK7w&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>